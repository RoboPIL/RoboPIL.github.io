<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GILD: Generalizable Imitation Learning with 3D Semantic Fields">
  <meta name="keywords" content="Robotic Manipulation, Language Models, Imitation Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GILD</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FV4ZJ9PVSV"></script>  
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FV4ZJ9PVSV');
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <script>

    function updateInteractive() {
      var task = document.getElementById("interative-menu").value;

      console.log("interactive", task)

      var img = document.getElementById("interactive-img");
      img.src = "media/interactive/" + 
                  task + 
                  "_crop.png"

      var html_1 = document.getElementById("interactive-html-1");
      html_1.src = "media/interactive/" + 
                  task + 
                  "_mask.html"

      var html_2 = document.getElementById("interactive-html-2");
      html_2.src = "media/interactive/" + 
                  task + 
                  "_feature.html"
    }
    
    function updateTracking() {
      var task = document.getElementById("tracking-menu").value;

      console.log("interactive", task)

      var vid = document.getElementById("tracking-vid");
      vid.src = "media/interactive/" + 
                  task + 
                  ".mp4"

      var html_1 = document.getElementById("tracking-html");
      html_1.src = "media/interactive/" + 
                  task + 
                  ".html"
    }



  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body onload="updateInteractive();">

<section class="hero">
  <div class="hero-body">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GILD: Generalizable Imitation Learning</br>with 3D Semantic Fields</h1>
          <!-- <h3 class="title is-4 conference-authors"><a target="_blank" href="https://www.corl2023.org/">CoRL 2023 (Oral)</a></h3> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://wangyixuan12.github.io/">Yixuan Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://binghao-huang.github.io/">Binghao Huang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://robopil.github.io/gild/">Guang Yin</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://kelestemur.com/">Tarik Kelestemur</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a target="_blank" href="https://yunzhuli.github.io/">Yunzhu Li</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois Urbana-Champaign,</span>
            <span class="author-block"><sup>2</sup>Boston Dynamics AI Institute</span><br>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a target="_blank" href="d3fields.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper [Coming Soon]</span>
                </a>
              </span>

            <!-- Arxiv Link. -->
            <span class="link-block">
              <a target="_blank" href="https://arxiv.org"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file"></i>
                </span>
                <span>ArXiv [Coming Soon]</span>
              </a>
            </span>

            <!-- Video Link. -->
            <span class="link-block">
              <a target="_blank" href="https://www.youtube.com"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-youtube"></i>
                </span>
                <span>Video [Coming Soon]</span>
              </a>
            </span>

            <!-- Code Link. -->
            <span class="link-block">
              <a target="_blank" href="https://github.com/WangYixuan12/gild"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>

            <!-- Colab Link. -->
            <span class="link-block">
              <a target="_blank" href="https://colab.research.google.com/drive/1Yk6uDg2So9A3yWALR7mF5dhl_KKR24eh?usp=sharing"
                 class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                  <img class="icon" src="static/images/colab.png" alt="Icon">
                </span>
                <span>Colab</span>
                </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-vcentered  is-centered">
          <video id="teaser" autoplay muted loop height="60%" width="60%">
            <source src="media/videos/teaser.mp4"
                    type="video/mp4">
          </video>
          </br>
        </div>
        <br>
        <h2 class="subtitle has-text-centered">
        GILD is an imitation learning framework capable of <b>category-level generalization</b> by using the <b>3D semantic fields</b>.
        </h2>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- spoon example -->
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/spoon_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/spoon_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/spoon_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/spoon_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- can example -->
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/can_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/can_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/can_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- knife example -->
        <!-- <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/knife_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/knife_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/knife_3.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!-- pen example -->
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/pen_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/pen_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/pen_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- shoe example -->
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/shoe_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/shoe_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/shoe_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- toothbrush example -->
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/toothbrush_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/toothbrush_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="media/videos/toothbrush_3.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<h2 class="subtitle has-text-centered">
</br>
  GILD shows <b>category-level generalization</b> capabilities across instances with diverse geometries, textures, and apprearances</br>in various challenging manipulation tasks requiring <b>semantic understanding</b>, such as spreading toothpaste.
</h2>


<section class="section">
  <!-- Abstract. -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning has shown remarkable capability in executing complex robotic manipulation tasks. However, existing frameworks often fall short in structured modeling of the environment, lacking explicit characterization of geometry and semantics, which limits their ability to generalize to unseen objects and layouts. To enhance the generalization capabilities of imitation learning agents, we introduce a novel framework in this work, incorporating explicit spatial and semantic information via 3D semantic fields. We begin by generating 3D descriptor fields from multi-view RGBD observations with the help of large foundational vision models. These high-dimensional descriptor fields are then converted into low-dimensional semantic fields, which aids in the efficient training of a diffusion-based imitation learning policy. The proposed method offers explicit consideration of geometry and semantics, enabling strong generalization capabilities in tasks that require category-level generalization, resolving geometric ambiguities, and attention to subtle geometric details. We evaluate our method across eight tasks involving articulated objects and instances with varying shapes and textures from multiple object categories. Our method proves its effectiveness by outperforming state-of-the-art imitation learning baselines on unseen testing instances by 57%. Additionally, we provide a detailed analysis and visualization to interpret the sources of performance gain and explain how our method can generalize to novel instances.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!-- Paper video. -->
  <br>
  <br>

  <!-- <div class="container is-max-widescreen">

    <div class="rows">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe src="https://www.youtube.com/embed/yNkIOwAO3GA"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>
  </div> -->

</section>

<section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">


    <div class="rows is-centered ">
      <div class="row is-full-width">
        <h2 class="title is-3">GILD</h2>

        <div class="content has-text-justified">
        </div>
        <img src="media/figures/method.png" class="interpolation-image" />
        </br>
        </br>
          <p class="content has-text-justified">
            <b>Method Overview.</b> The top row shows a sequence of real policy rollouts in the aligning shoe task. At one time step, we take in multi-view RGBD observations first and then extract the 3D descriptor field, where each point has corresponding high-dimensional semantic features. We then select reference features from 2D reference images. By computing the cosine similarity between the descriptor field and 2D reference semantic features, we could obtain several similarity fields. Concatenating similarity fields with the point cloud, the representation is input into PointNet++ and diffusion policy to output predicted actions.
          </p>
        
      <br>
      <br>

      <h2 class="title is-3">Interactive Visualization</h2>

      <div class="columns">
        <div class="column has-text-centered">

          Visualize D<sup>3</sup>Fields for
          <div class="select is-small is-rounded">     
            <select id="interative-menu" onchange="updateInteractive()">
            <option value="shoe" selected="selected">shoes</option>
            <option value="mug">mugs</option>
            <option value="fork">forks</option>
            </select>
          </div>
        </div>

      </div>

      <div class="columns">
        <div class="column has-text-centered">
          <p style="text-align:center;">
            <!-- <img id="interactive-img", src="media/interactive/shoe_crop.png" class="interpolation-image" /> -->
            <iframe id="interactive-img" src="media/interactive/shoe_crop.png" width=320 height=320 frameborder="0"></iframe>
          </p>
        </div>
        <div class="column has-text-centered">
          <iframe id="interactive-html-1" src="media/interactive/shoe_mask.html" width=400 height=300 frameborder="0"></iframe>
          <p style="text-align:center;">
            Mask Field
          </p>
        </div>
        <div class="column has-text-centered" id="second-iframe-container">
          <iframe id="interactive-html-2" src="media/interactive/shoe_feature.html" width=400 height=300 frameborder="0"></iframe>
          <p style="text-align:center;">
            Descriptor Field
          </p>
        </div>
      </div>

      <br>

      <!-- <div class="columns">
        <div class="column has-text-centered">

          Visualize tracking for 
          <div class="select is-small is-rounded">     
            <select id="tracking-menu" onchange="updateTracking()">
            <option value="example_1" selected="selected">example 1</option>
            <option value="example_2">example 2</option>
            </select>
          </div>
        </div>

      </div>

      <div class="columns">
        <div class="column is-half has-text-centered">
          <p style="text-align:center;">
            <video id="tracking-vid" width="100%" height="100%" controls autoplay loop muted>
              <source src="media/interactive/example_1.mp4" type="video/mp4">
            </video>
            3D Tracking Visualization (Projected to Image Space)
          </p>
          </p>
        </div>
        <div class="column is-half has-text-centered">
          <iframe id="tracking-html" src="media/interactive/example_1.html" width=500 height=315 frameborder="0"></iframe>
          <p style="text-align:center;">
            3D Tracking Trace Visualization
          </p>
        </div>
      </div> -->


    </div>
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">


    <div class="rows is-centered ">
      <div class="row is-full-width">

        <h2 class="title is-3">Interactive Visualization</h2>

        <div class="columns">
          <div class="column has-text-centered">

            Visualize D<sup>3</sup>Fields for
            <div class="select is-small is-rounded">     
              <select id="interative-menu" onchange="updateInteractive()">
              <option value="shoe" selected="selected">shoes</option>
              <option value="mug">mugs</option>
              <option value="fork">forks</option>
              </select>
            </div>
          </div>

        </div>

        <div class="columns">
          <div class="column is-half has-text-centered">
            <p style="text-align:center;">
              <img id="interactive-img", src="media/interactive/shoe.png" class="interpolation-image" />
            </p>
          </div>
          <div class="column has-text-centered">
            <iframe id="interactive-html-1" src="media/interactive/shoe_mask.html" width="100%" height="300" frameborder="0"></iframe>
            <p style="text-align:center;">
              Mask Field
            </p>
          </div>
          <div class="column has-text-centered" id="second-iframe-container">
            <iframe id="interactive-html-2" src="media/interactive/shoe_feature.html" width="100%" height="300" frameborder="0"></iframe>
            <p style="text-align:center;">
              Descriptor Field
            </p>
          </div>
        </div>
        
        
    </div>
  </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">
      <h2 class="title is-3">Execution under Disturbances</h2>
      
      <p class="content has-text-justified">
        Our framework is robust to external disturbances. We show that our framework could recover from disturbances in the following videos.
      </p>
      
      <div class="columns">
        <div class="column has-text-centered">
          <video id="dist1"
            controls
            muted
            autoplay
            loop
            width="99%">
            <source src="media/videos/perturbation_shoe.mp4" 
            type="video/mp4">
          </video>
        </div>
    
        <div class="column has-text-centered">
          <video id="dist2"
            controls
            muted
            autoplay
            loop
            width="99%">
            <source src="media/videos/perturbation_utensils.mp4" 
            type="video/mp4">
          </video>
        </div>
  </div>
  </div>
</section> -->

<!-- <section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">
      <h2 class="title is-3">Emergent Behavioral Capabilities</h2>
      
      <p class="content has-text-justified">
        <li><strong>Estimating Physical Properties</strong>: given two blocks of unknown mass, the robot is tasked to conduct physics experiments using the available tools to determine which block is heavier.</li>
        <li><strong>Behavioral Commonsense Reasoning</strong>: during a task where robot is setting the table, the user can specify behavioral preferences such as "I am left-handed", which requires the robot to comprehend its meaning in the context of the task.</li>
        <li><strong>Fine-grained Language Correction</strong>: for tasks that require high precision such as "covering the teapot with the lid", user can give precise instructions to the robot such as "you're off by 1cm".</li>
        <li><strong>Multi-step Visual Program</strong>: given a task "open the drawer precisely by half" where there is insufficient information because object models are not available, the robot can come up with multi-step manipulation strategies based on visual feedback that first opens the drawer fully while recording handle displacement, then close it back to the mid-point to satisfy the requirement.</li>
      </p>
      <br>
      <div style="text-align: center;">
        <img src="media/figures/emergent.png" class="interpolation-image" style="width: 70%; height: auto;"/>
      </div>
    </div>

  </div>

</section>

<section class="section">
  <div class="container is-max-widescreen">
  <div class="row">
    <h2 class="title is-3">
      Prompts
    </h2>
    <p class="content has-text-justified">
        Prompts in Real-World Environments:
        <br>
        <a href="prompts/real_planner_prompt.txt">Planner</a> |
        <a href="prompts/real_composer_prompt.txt">Composer</a> |
        <a href="prompts/real_parse_query_obj_prompt.txt">Parse Query Object</a> |
        <a href="prompts/real_get_affordance_map_prompt.txt">Get Affordance Maps</a> |
        <a href="prompts/real_get_avoidance_map_prompt.txt">Get Avoidance Maps</a> |
        <a href="prompts/real_get_rotation_map_prompt.txt">Get Rotation Maps</a> |
        <a href="prompts/real_get_velocity_map_prompt.txt">Get Velocity Maps</a> |
        <a href="prompts/real_get_gripper_map_prompt.txt">Get Gripper Maps</a>
    </p>
    <p class="content has-text-justified">
        Prompts in Simulation Environments (planners are not used in simulation):
        <br>
        <a href="prompts/sim_composer_prompt.txt">Composer</a> |
        <a href="prompts/sim_parse_query_obj_prompt.txt">Parse Query Object</a> |
        <a href="prompts/sim_get_affordance_map_prompt.txt">Get Affordance Maps</a> |
        <a href="prompts/sim_get_avoidance_map_prompt.txt">Get Avoidance Maps</a> |
        <a href="prompts/sim_get_rotation_map_prompt.txt">Get Rotation Maps</a> |
        <a href="prompts/sim_get_velocity_map_prompt.txt">Get Velocity Maps</a> |
        <a href="prompts/sim_get_gripper_map_prompt.txt">Get Gripper Maps</a>
    </p>
  </div>
  </div>
</section>  -->


<section class="section" id="BibTeX">
  <div class="container is-max-widescreen content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2023gild,
      title={GILD: Generalizable Imitation Learning with 3D Semantic Fields},
      author={Wang, Yixuan and Huang, Binghao and Yin, Guang and Kelestemur, Tarik and Li, Yunzhu},
      journal={arXiv preprint arXiv:},
      year={2024}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>, <a href="https://peract.github.io/">PerAct</a>, <a href="https://voxposer.github.io/">VoxPoser</a>, and <a href="https://robopil.github.io/d3fields/">D<sup>3</sup>Fields</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
